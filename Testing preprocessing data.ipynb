{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wf\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import delta\n",
    "from python_speech_features import logfbank\n",
    "import scipy.io.wavfile as wav\n",
    "#import scipy.io.m4afile as m4a\n",
    "import glob\n",
    "import scipy.io\n",
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceActivityDetector():\n",
    "    \"\"\" Use signal energy to detect voice activity in wav file \"\"\"\n",
    "    \n",
    "    def __init__(self, wave_input_filename):\n",
    "        self._read_wav(wave_input_filename)._convert_to_mono()\n",
    "        self.sample_window = 0.02 #20 ms\n",
    "        self.sample_overlap = 0.01 #10ms\n",
    "        self.speech_window = 0.5 #half a second\n",
    "        self.speech_energy_threshold = 0.6 #60% of energy in voice band\n",
    "        self.speech_start_band = 300\n",
    "        self.speech_end_band = 3000\n",
    "           \n",
    "    def _read_wav(self, wave_file):\n",
    "        self.rate, self.data = wf.read(wave_file)\n",
    "        self.channels = len(self.data.shape)\n",
    "        self.filename = wave_file\n",
    "        return self\n",
    "    \n",
    "    def _convert_to_mono(self):\n",
    "        if self.channels == 2 :\n",
    "            self.data = np.mean(self.data, axis=1, dtype=self.data.dtype)\n",
    "            self.channels = 1\n",
    "        return self\n",
    "    \n",
    "    def _calculate_frequencies(self, audio_data):\n",
    "        data_freq = np.fft.fftfreq(len(audio_data),1.0/self.rate)\n",
    "        data_freq = data_freq[1:]\n",
    "        return data_freq    \n",
    "    \n",
    "    def _calculate_amplitude(self, audio_data):\n",
    "        data_ampl = np.abs(np.fft.fft(audio_data))\n",
    "        data_ampl = data_ampl[1:]\n",
    "        return data_ampl\n",
    "        \n",
    "    def _calculate_energy(self, data):\n",
    "        data_amplitude = self._calculate_amplitude(data)\n",
    "        data_energy = data_amplitude ** 2\n",
    "        return data_energy\n",
    "        \n",
    "    def _znormalize_energy(self, data_energy):\n",
    "        energy_mean = np.mean(data_energy)\n",
    "        energy_std = np.std(data_energy)\n",
    "        energy_znorm = (data_energy - energy_mean) / energy_std\n",
    "        return energy_znorm\n",
    "    \n",
    "    def _connect_energy_with_frequencies(self, data_freq, data_energy):\n",
    "        energy_freq = {}\n",
    "        for (i, freq) in enumerate(data_freq):\n",
    "            if abs(freq) not in energy_freq:\n",
    "                energy_freq[abs(freq)] = data_energy[i] * 2\n",
    "        return energy_freq\n",
    "    \n",
    "    def _calculate_normalized_energy(self, data):\n",
    "        data_freq = self._calculate_frequencies(data)\n",
    "        data_energy = self._calculate_energy(data)\n",
    "        #data_energy = self._znormalize_energy(data_energy) #znorm brings worse results\n",
    "        energy_freq = self._connect_energy_with_frequencies(data_freq, data_energy)\n",
    "        return energy_freq\n",
    "    \n",
    "    def _sum_energy_in_band(self,energy_frequencies, start_band, end_band):\n",
    "        sum_energy = 0\n",
    "        for f in energy_frequencies.keys():\n",
    "            if start_band<f<end_band:\n",
    "                sum_energy += energy_frequencies[f]\n",
    "        return sum_energy\n",
    "    \n",
    "    def _median_filter (self, x, k):\n",
    "        assert k % 2 == 1, \"Median filter length must be odd.\"\n",
    "        assert x.ndim == 1, \"Input must be one-dimensional.\"\n",
    "        k2 = (k - 1) // 2\n",
    "        y = np.zeros ((len (x), k), dtype=x.dtype)\n",
    "        y[:,k2] = x\n",
    "        for i in range (k2):\n",
    "            j = k2 - i\n",
    "            y[j:,i] = x[:-j]\n",
    "            y[:j,i] = x[0]\n",
    "            y[:-j,-(i+1)] = x[j:]\n",
    "            y[-j:,-(i+1)] = x[-1]\n",
    "        return np.median (y, axis=1)\n",
    "        \n",
    "    def _smooth_speech_detection(self, detected_windows):\n",
    "        median_window=int(self.speech_window/self.sample_window)\n",
    "        if median_window%2==0: median_window=median_window-1\n",
    "        median_energy = self._median_filter(detected_windows[:,1], median_window)\n",
    "        return median_energy\n",
    "        \n",
    "    def convert_windows_to_readible_labels(self, detected_windows):\n",
    "        \"\"\" Takes as input array of window numbers and speech flags from speech\n",
    "        detection and convert speech flags to time intervals of speech.\n",
    "        Output is array of dictionaries with speech intervals.\n",
    "        \"\"\"\n",
    "        speech_time = []\n",
    "        is_speech = 0\n",
    "        for window in detected_windows:\n",
    "            if (window[1]==1.0 and is_speech==0): \n",
    "                is_speech = 1\n",
    "                speech_label = {}\n",
    "                speech_time_start = window[0] / self.rate\n",
    "                speech_label['speech_begin'] = speech_time_start\n",
    "                print(window[0], speech_time_start)\n",
    "                #speech_time.append(speech_label)\n",
    "            if (window[1]==0.0 and is_speech==1):\n",
    "                is_speech = 0\n",
    "                speech_time_end = window[0] / self.rate\n",
    "                speech_label['speech_end'] = speech_time_end\n",
    "                speech_time.append(speech_label)\n",
    "                print(window[0], speech_time_end)\n",
    "        return speech_time\n",
    "      \n",
    "    def plot_detected_speech_regions(self):\n",
    "        \"\"\" Performs speech detection and plot original signal and speech regions.\n",
    "        \"\"\"\n",
    "        data = self.data\n",
    "        detected_windows = self.detect_speech()\n",
    "        data_speech = np.zeros(len(data))\n",
    "        it = np.nditer(detected_windows[:,0], flags=['f_index'])\n",
    "        while not it.finished:\n",
    "            data_speech[int(it[0])] = data[int(it[0])] * detected_windows[it.index,1]\n",
    "            it.iternext()\n",
    "        plt.figure()\n",
    "        plt.plot(data_speech)\n",
    "        plt.plot(data)\n",
    "        plt.show()\n",
    "        return self\n",
    "       \n",
    "    def detect_speech(self):\n",
    "        \"\"\" Detects speech regions based on ratio between speech band energy\n",
    "        and total energy.\n",
    "        Output is array of window numbers and speech flags (1 - speech, 0 - nonspeech).\n",
    "        \"\"\"\n",
    "        detected_windows = np.array([])\n",
    "        sample_window = int(self.rate * self.sample_window)\n",
    "        sample_overlap = int(self.rate * self.sample_overlap)\n",
    "        data = self.data\n",
    "        sample_start = 0\n",
    "        start_band = self.speech_start_band\n",
    "        end_band = self.speech_end_band\n",
    "        while (sample_start < (len(data) - sample_window)):\n",
    "            sample_end = sample_start + sample_window\n",
    "            if sample_end>=len(data): sample_end = len(data)-1\n",
    "            data_window = data[sample_start:sample_end]\n",
    "            energy_freq = self._calculate_normalized_energy(data_window)\n",
    "            sum_voice_energy = self._sum_energy_in_band(energy_freq, start_band, end_band)\n",
    "            sum_full_energy = sum(energy_freq.values())\n",
    "            speech_ratio = sum_voice_energy/sum_full_energy\n",
    "            # Hipothesis is that when there is a speech sequence we have ratio of energies more than Threshold\n",
    "            speech_ratio = speech_ratio>self.speech_energy_threshold\n",
    "            detected_windows = np.append(detected_windows,[sample_start, speech_ratio])\n",
    "            sample_start += sample_overlap\n",
    "        len_detected_windows =  len(detected_windows)//2\n",
    "        print(len_detected_windows)\n",
    "        detected_windows = detected_windows.reshape(len_detected_windows,2)\n",
    "        detected_windows[:,1] = self._smooth_speech_detection(detected_windows)\n",
    "        return detected_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_SVD(data,window_size):\n",
    "    df = []\n",
    "    for i in range(int(len(data)/window_size)):\n",
    "        complexity = nk.complexity(data[i*window_size:(i+1)*window_size])\n",
    "        df.append(complexity['Entropy_SVD'])\n",
    "    df = pd.DataFrame(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_entropy(data,window_size):\n",
    "    df = []\n",
    "    for i in range(int(len(data)/window_size)):\n",
    "        complexity = nk.complexity(data[i*window_size:(i+1)*window_size],spectral=True,shannon=False,sampen=False,multiscale=False,svd = False,correlation=False,\n",
    "                          higushi = False,petrosian=False,fisher = False,hurst = False,dfa= False,lyap_r=False,lyap_e =False)\n",
    "        df.append(complexity['Entropy_Spectral'])\n",
    "    df = pd.DataFrame(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kurtosis(data,window_size):\n",
    "    #data = pd.DataFrame(data)\n",
    "    df=[]\n",
    "    for i in range(int(len(data)/window_size)):\n",
    "        df.append(data[i*window_size:(i+1)*window_size].kurtosis())\n",
    "    df = pd.DataFrame(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(data,window_size):\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(int(len(data)/window_size)):\n",
    "        dt = np.array(data[i*window_size:(i+1)*window_size])\n",
    "        window = np.ones((window_size,))/float(window_size)\n",
    "        dt = pd.DataFrame(np.convolve(dt, window,mode='valid'))\n",
    "        df = pd.concat([df,dt])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_square(data,window_size):\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(int(len(data)/window_size)):\n",
    "        dt = np.power(data[i*window_size:(i+1)*window_size],2)\n",
    "        window = np.ones((window_size,))/float(window_size)\n",
    "        dt = pd.DataFrame(np.sqrt(np.convolve(dt, window,mode='valid')))\n",
    "        df = pd.concat([df,dt])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30119\n"
     ]
    }
   ],
   "source": [
    "name_file = 'EEG .mat files/u_Filters.mat' #put the file .mat name\n",
    "audio_file = 'Audio wav files/mason-1-u.wav'\n",
    "path = '/home/guatam-admin/Vijay_BCI/Data-Mason-1/' #put the directory\n",
    "(rate,sig) = wav.read(path+audio_file)\n",
    "mfcc_feat = mfcc(sig,rate,winstep=0.01)\n",
    "mf = pd.DataFrame(mfcc_feat)\n",
    "v = VoiceActivityDetector(path+audio_file)\n",
    "label = pd.DataFrame(v.detect_speech())\n",
    "label.columns = ['time','label']\n",
    "if len(mf)!=len(label):\n",
    "    fill_na = pd.DataFrame({'time':[label['time'][len(label)-1]+120.0],\n",
    "                       'label':[label['label'][len(label)-1]]})\n",
    "    label = label.append(fill_na).reset_index(drop=True)\n",
    "mat = scipy.io.loadmat(path+name_file)\n",
    "mat = {k:v for k, v in mat.items() if k[0]!='_'}\n",
    "names = list(mat.keys())\n",
    "df = pd.DataFrame()\n",
    "for key in names[:-8]:\n",
    "    value = mat[key]\n",
    "    value = pd.DataFrame(value)\n",
    "    df = pd.merge(df,value,how='right',right_index=True,left_index=True)\n",
    "df.columns = names[:-8]\n",
    "df_zero = pd.DataFrame()\n",
    "for name in df.columns:\n",
    "    zero = librosa.feature.zero_crossing_rate(df[name].values,frame_length=100,hop_length=10)\n",
    "    zero = pd.DataFrame(np.transpose(zero))\n",
    "    df_zero = pd.merge(df_zero,zero,how='right',right_index=True,left_index=True)\n",
    "df_zero.columns = [column+'_zero' for column in df.columns]\n",
    "df_zero = df_zero*int(100)\n",
    "df_avg = pd.DataFrame()\n",
    "for name in df.columns:\n",
    "    avg = average(df[name].values,window_size=10)\n",
    "    df_avg = pd.concat([df_avg,avg],axis=1)\n",
    "df_avg.columns = [column+'_avg' for column in df.columns]\n",
    "df_rms = pd.DataFrame()\n",
    "for name in df.columns:\n",
    "    rms = root_mean_square(df[name].values,window_size=10)\n",
    "    df_rms = pd.concat([df_rms,rms],axis=1)\n",
    "df_rms.columns = [column+'_rms' for column in df.columns]\n",
    "df_spectral = pd.DataFrame()\n",
    "for name in df.columns:\n",
    "    spectral = spectral_entropy(df[name].values,window_size=10)\n",
    "    #rms = pd.DataFrame(np.transpose(zero))\n",
    "    df_spectral = pd.concat([df_spectral,spectral],axis=1)\n",
    "df_spectral.columns = [column+'_spectral' for column in df.columns]\n",
    "df_kurt = pd.DataFrame()\n",
    "for name in df.columns:\n",
    "    kurt = kurtosis(df[name],window_size=10)\n",
    "    #rms = pd.DataFrame(np.transpose(zero))\n",
    "    df_kurt = pd.concat([df_kurt,kurt],axis=1)\n",
    "df_kurt.columns = [column+'_kurt' for column in df.columns]\n",
    "df_rms = df_rms.reset_index(drop=True)\n",
    "df_zero = df_zero.reset_index(drop=True)\n",
    "df_avg = df_avg.reset_index(drop=True)\n",
    "df_kurt = df_kurt.reset_index(drop=True)\n",
    "df_spectral = df_spectral.reset_index(drop=True)\n",
    "df_kurt = df_kurt[(len(df_kurt)-len(mf)):len(df_kurt)].reset_index(drop=True)\n",
    "df_spectral = df_spectral[(len(df_spectral)-len(mf)):len(df_spectral)].reset_index(drop=True)\n",
    "df_rms = df_rms[(len(df_rms)-len(mf)):len(df_rms)].reset_index(drop=True)\n",
    "df_zero = df_zero[(len(df_zero)-len(mf)):len(df_zero)].reset_index(drop=True)\n",
    "df_avg = df_avg[(len(df_avg)-len(mf)):len(df_avg)].reset_index(drop=True)\n",
    "final_data = pd.DataFrame()\n",
    "final_data = pd.concat([df_rms,df_zero,df_avg,df_spectral,df_kurt,label],axis=1)\n",
    "final_data = final_data.drop(['time'],axis=1)\n",
    "final_data.to_csv('/home/guatam-admin/Vijay_BCI/Vowel_data/Mason/final_u.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv('/home/guatam-admin/Vijay_BCI/Vowel_data/Mason/final_i.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_na = pd.DataFrame({'time':[label['time'][len(label)-1]+120.0],\n",
    "                       'label':[label['label'][len(label)-1]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30053 entries, 0 to 30052\n",
      "Columns: 156 entries, Fp1_rms to label\n",
      "dtypes: float64(156)\n",
      "memory usage: 35.8 MB\n"
     ]
    }
   ],
   "source": [
    "final_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
